apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: iris-ml-pipeline-
spec:
  entrypoint: ml-pipeline
  
  # Define 1 GB shared volume
  volumeClaimTemplates:                 
  - metadata:
      name: data                     
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
          
  templates:
  - name: ml-pipeline
    # DAG template to define stages of the Machine Learning Pipeline
    dag:
      tasks:
      - name: preprocess-data
        template: preprocess
      - name: train-model
        template: train
        dependencies: [preprocess-data]
      - name: evaluate-model
        template: evaluate
        dependencies: [train-model]

  # Step 1: Preprocess Data
  - name: preprocess
    container:
      image: python:3.8-slim
      command: [bash, -c]
      args:
        - |
          pip install pandas scikit-learn
          python -c "
          import pandas as pd
          from sklearn.datasets import load_iris
          
          # Load Iris dataset
          iris = load_iris()
          df = pd.DataFrame(iris.data, columns=iris.feature_names)
          df['target'] = iris.target
          
          # Save preprocessed data
          df.to_csv('/mnt/data/iris_prepared.csv', index=False)
          print('Iris dataset preprocessing completed.')
          "
      volumeMounts:
      - name: data
        mountPath: /mnt/data

  # Step 2: Train Model
  - name: train
    container:
      image: python:3.8-slim
      command: [bash, -c]
      args:
        - |
          pip install pandas scikit-learn joblib
          python -c "
          import pandas as pd
          from sklearn.model_selection import train_test_split
          from sklearn.ensemble import RandomForestClassifier
          import joblib
          
          # Load preprocessed data
          df = pd.read_csv('/mnt/data/iris_prepared.csv')
          X = df.drop('target', axis=1)
          y = df['target']
          
          # Train model
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
          model = RandomForestClassifier(n_estimators=100, random_state=42)
          model.fit(X_train, y_train)
          
          # Save model
          joblib.dump(model, '/mnt/data/iris_model.joblib')
          print('Model training completed.')
          "
      volumeMounts:
      - name: data
        mountPath: /mnt/data
    
    # Publish the model as an artifact
    outputs:
      artifacts:
      - name: output
        path: /mnt/data/iris_model.joblib
        
  # Step 3: Evaluate Model
  - name: evaluate
    container:
      image: python:3.8-slim
      command: [bash, -c]
      args:
        - |
          pip install pandas scikit-learn joblib
          python -c "
          import pandas as pd
          from sklearn.metrics import accuracy_score
          import joblib
          
          # Load preprocessed data and model
          df = pd.read_csv('/mnt/data/iris_prepared.csv')
          X = df.drop('target', axis=1)
          y = df['target']
          model = joblib.load('/mnt/data/iris_model.joblib')
          
          # Evaluate model
          y_pred = model.predict(X)
          accuracy = accuracy_score(y, y_pred)
          
          print(f'Model Evaluation Results:')
          print(f'Accuracy: {accuracy}')
          
          # Save evaluation results
          with open('/mnt/data/evaluation_results.txt', 'w') as f:
            f.write(f'Accuracy: {accuracy}\n')
          "
      volumeMounts:
      - name: data
        mountPath: /mnt/data
